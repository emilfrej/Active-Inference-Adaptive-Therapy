---
title: "SocultPaperV2"
output: pdf_document
date: "2024-05-19"
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())


# set the directory to visualizations folder


pacman::p_load(tidyverse, ggnewscale)
theme_set(theme_classic())


#set colors
adt_col <- "green"
long_col <- "red"
medium_col <- "skyblue"
short_col = "violet"

strat_colors <- c("ADT" = adt_col, "Long" = long_col, "Medium" = medium_col, "Short" = short_col)
contrast_colors <- c("long_vs_adt" = long_col, "medium_vs_adt" = medium_col, "short_vs_adt" = short_col)

```

# Introduction

## 

### What is the adapative cancer therapy

Worldwide, cancer is the cause of 1 out 6 deaths. Of these cancer deaths an estimated 90% are due to development of drug resistance [@bukowski2020]. While intial cancer treatment usually shows positive response in tumor burden, drug resistance develops due. To highlight the inefficincy of traditional approaches, [@stanková2019] models cancer treatment game theorict contest between a physician and a tumor, where physicians move on each round is to apply a certain treatment, and a tumor makes an adaption. While it is a "Stackelberg game", a game where one player is the leader (the physician) and another player is a follower (the tumor), is assymerty is rarely exploited. Instead of using their advantage to steer the evolutionary pressures placed on tumors, the physician lets the tumor not only adapt to the current round of the game but also to future rounds of the game. The advantage of leading the game is thereby lost. The authors aptly analogize the current practice:

> *"Consider cancer treatment as a rock-paper-scissors game in which almost all cells within the cancer play, for example, “paper.” It is clearly advantageous for the treating physician to play “scissors.” Yet, if the physician only plays “scissors,” the cancer cells can evolve to the unbeatable resistance strategy of “rock.”"* [@stanková2019]

*Adaptive Therapy* is a approach to cancer treatment based on controlling the intra-tumoral evolutionary dynamics. By leveraging that cancer cells can incur a fitness cost to evovling mechanisms that yield resistance to drugs. For example it has been shown that tumor cells can mutate to increased expression of PGP membrane pump, which uses ATP to move drugs out of the cell. While this makes cell more resistant to treatment, it also comes at metabolic cost. [@gatenby2009] found that PGP activity was the culprit of approximately 50% of cell metabolism. As a result, if resistant and non-resistant cells are competing for space and resources, drug-sensitive cells should over time outcompete resistant cells. Apative Therapy utilizes this darwinian competition to make cancer fight itself. Thus the dream-sceneario of this adaptive therapy is not to eradicate cancer, but instead make it a controllable chronic disease.

[![Figure 1: From Zhang et al. 2023. Panel A shows a typical "Maximal Tolerable Dose" treatment protocol. While the initial response in tumor burden is promising, a compettive release of resistant cells ensures. Panel B shows Adaptive Therapy approach with a small tumor burden. Panel C shows adaptive therapy with a high tumor burden, which has been theorized to further increase the suppression of resistance cells through darwinian compettetion.](images/Screenshot%202024-05-20%20at%2008.15.19.png){width="686"}](https://doi.org/10.1016/j.critrevonc.2023.104192)

Initial results from pilot clinical trial on metastatic castrate-resistant prostate cancer patients are promising. Intitial results showing both less cumuluative dosages and longer survival in comparison similiar group of patients recieving standard care. Firstly, patients were only involved if they showed a substainal positive response to treatment. The trial has then been utilizing a range-bounded treatment rule. If the bloodmarker *Prostate-specific Antigen* (PSA), a proxy of tumor burden, increases back to pre-trial levels, treatment is applied until PSA drops to 50% of pre–trial levels [@zhang2017]. The trial is expected to run until december 2024 [@h.leemoffittcancercenterandresearchinstitute2024].

### Desired qualities of models

While the trial reported by [@zhang2017] only utilized a single drug, key researchers in researchers in Adapative Therapy has produced a review of the use of mathematical modelling in the field, and among other things, indentified that modelling multidrug treatments is a necessity of future models. Additionally, they argue that it is unlikely that any treatment approach can accomplish delaying the emergence of resistant cells, lower the tumor burden and minizmize the toxicity. Given that patients likely differ in their ability to tolerate tumor burden and the toxicity of drugs and the evolutioanry dynamics of the cancers that they carry differ, ,odels would ideally therefore have to trade-off each these factors given a specific patient. This will require fitting data on invidual patients. Lotke-volterra models have been fitted frequently.

#### biological factors

Another important aspect of modelling, is illumanitng the actual comppetive disadvantage that resistant cells are. While larger tumor sizes are thought to increase the suppresion of resistant cells, the dynamics are likely much more complex. Factors such as the spatial configuration of actual cells and the range of the molecular influence they yield of each other. It is also crucial that these actually incur a fitness cost, however other authiors argue that adaptive therapy might still be able to delay time-to-progression if this is not the case. Comptettion isn't neccesarily strong if the tumor isn't at carrying capacity.

\*\* CONTROLLING THE RESPONSE TO TREATMENT IS PARAMOUNT. MOUNTAIN CAR PROBLEM\*\*

Gene-expression has been shown to change in cells as a result of treatment, which further complicates modelling the adaptive therapy as case of resistant vs non resistant cells. Phenotypic plasticity should therefore also be accounted for. Another biological factor that should be accounted for is sourrind tissue. For example, prostate cancer cells in bone can utilzied such as the transforming growth factor $\beta$ can accelerate the proliferation of cancer cells.

\*\* You can keep throwing layers at POMDPs\*\*

The efficay adapative therapy depends strongly on initial resistance rates, and deciding to opt for control strategy such as adpative therapy would be beneficial if made early. THis however necessitates predicting what patients would respond better to adaptive therapy and who benefit better from the other treatment protocols, such as standard maximum tolerable dose protocol.

#### How to construct dosing protocols

High tumor burdens might also come with other costs, such as increasing the risk of new metastates or simply by the fact that more cells increase the chance total amount of mutations happening. Adapative therapy also depends on frequent monitoring, and could benefit from the use of different testing protocols.

Robustness to changes to in plans due to machine failure or tother practical constraints.

There is need to include multi-drug treatment protocols in adaptive therapy, but the number of possible permtuations at each point in time grows extremely fast when more treatment options are introduced. A potential solution to this problem is constructing a treatment protocol that steers the tumor in cycle, so that the conditions at the start of one treatment block is indentical to how conditions of the prior block. In principle only one block would have to be designed then. \*\* this is a non-steady-state equlibirum \*\*

#### Constructing real time prediciton

Prediciting individual patient repsonses real-time would greatly enhance adaptive therapy since dose modulation could be indivdualized further and evolutionary dynamics controllable with more precision. Using relevant biomarkers would be crucial in this regard \*\* all observable consequences also generate information \*\* Any chosen model must be able to be calibrated and validated before hand. When to time the collection of biomarks also seems to be in issue, since the prostate trial found that treatment would at times overshoot, since biomarkers were collected too late, and the PSA levels were dropped well-below 50%. This likely leads to poorer clinical performance. The link between biomarkers and actual tumor progression is not certain neither, meaning that decidnig when to treat directly on the basis of a biomarker might not be optimal.

A key issue going forward is rethiking how data on patients is collected. It will be crucial to collect data not only to detect progression, but to collect data that will be usefull for future decisions too. \*\* this is EFE\*\* Quantifying the unceartinty in the models belief and the consequences of its suggested actions is also paramount.

### What are POMDPs in general

Partially Observable Markov Decision Processes (POMPD) is class of controller models that model and underlying markovian process, that in disctrete time and state enviroment, the next step of the system only depends on the current step. Crucially for partial orbservability is crucial facet of these models, and refers to the fact that these models don't directly observe the actual enviroment or markovian process, but instead only potentially noisy signals emitted by it while trying to manipulate the evivorment [@åström1969]. This allows these models to differiate an orbserved signal from what it "believes" about the enviorment and use a single reward function trade off unceartinty for achieveing a certain goal state [@kaelbling1998] while yielding bayes optimal beliefs. For example, if discretized a, POMDP could understand a PSA reading as noised signal of actual tumor state, and thus try to control to tumor state rather than the PSA reading. While POMDPs are typically difficult to solve analytically various approximate approaches exist.

### Using active inference to solve pompds

One approximate solutions, of these is born out of the field of neuroscience litterature. The field which has come to be know as active inference suggests that the brain could by using a varitional approach. By minimizing two objective functions. *Free Energy* (EFE) as measure of model and past sensory inputs, and *Expected Free Energy* (EFE) which evaluates future courses of actions against a set preferred observations. Active Inference has been used to model psychopathology [@dacosta2020] but also applied to control scenearious such as the mountain-car problem [@friston2009] and, albeit augmented with deep-learning, robotics control \@[@çatal2020]. These have been implemneted in MATLAB and recently in Python with the python package pymdp [[@heins2022a] and [@heins2022].

Typically POMDPs are modelled for discrete state spaces. Mathematically they are described as a joint probability:

$$
p(o,s,u;\phi)
$$

where $o$ are observations, $s$ are hidden states, $u$ are "control states" (states that an agent can influence) and $\phi$ are the hyperparameters of the model, such as $\alpha$ typiccaly used as 'inverse temperature' i.e. how deterministicly the model selects actions. By conditioning on certain observations, the POMDP is solvable by various approximations schemes for the optimal posterior beliefs over what the underlying hidden states are and what the optimal course of action is given a set of preferences. For example, a POMPD could model the joint probability of observing a certain amount of tumor burden in a patient, given some hidden states, such as the how resistancy of the underlying tumors, and whether a certain treatment was applied. Disregarding computability this can be done for any time horizon. Due to considering time and states discrete, this joint probability can be made tractable for a time horizons by factorizing the joint probability into the following categorical probability distributions:

-   A likelihood model $A$. Ususally modelled as a set of arrays where each array corresponds to an observation modality describes the how observations map to a particular state. For example how one modality could be PSA readings, and its likelihood array describes how likely different test results are under different tumor burdens. It can both be modelled as a perfect signal of the tumor burden, ie the same tumor burden always gives the same test result, but it could also be implemented as noised signal. If multiple states are modelled, each likelihood modality is an array with a dimension corresponding to the number of possible observations of that modality, and for each hidden state another dimension is added with the same length as the number of possible hidden states. In this way, every combination of state can be mapped to an observation.

-   A transition model $B$. It describes the probability of state transitioning to another on any particular timestep. This also encodes how actions are expected to influence transition probabilites. It could describe how a tumor is likely to evolve from one timestep to next depending whether treatments is being applied. The transition model is usually coded as collection of three-dimensional arrays, a first dimension for the next state, a dimension for the current state, and a third dimension with the length of each action that would influence transition probabilities of the state. Modelling the transition probabilities would depend on whether treatment is being applied or not.

-   A prior over preferred states $C$. A particularity of these models is that utility is specified in probabilities. This prior is set over certain observations, meaning that the model artificially expects to see certain observations. As a result, this drives the models behavior to act in ways that bring it close these expectations. At a first pass, describing a goal in terms of probabilities seems odd, but it could be considered a fundamental property of self-organizing systems. For example, to stay a live, I would have to spend time states where my tumor burden is low, even though in all likelihood, given enough time, I would come to develop cancer. Crucially, it allows for inferring what actions would bring about me spending time in states with low tumor burdens.

-   A prior over initial states $D$. These are vectors of probabilities of intial beliefs. In continuation with example above, this component would specify how probable different levels of tumor burden before interacting with the patient.

The POMPD can be solved at any time step by minimizing two measures, *Variational Free Energy* (VFE) and *Expected Free Energy* (EFE). VFE is an upper bound on *surprisal,* and is approximated to infer the most likely current state given an observation, the likelihood model, and the prior over either initial states if no earlier orbsevations have been made. Otherwise the the precedding posterior over states is used as the current prior [@smith2022]. VFE scores how well the models representation aligns with a set of observations, and by using different approximate posteriors over states, choosing the approximate which minizimes VFE will approximate bayesian belief updating [@dacosta2020]. EFE instead score, plans on how to act and their expected outcomes. EFE is used to construct a posterior distribution over what policy is most preferred. Since the model is equipped with $C$, the set of prior preferences over observations, the distinguishing between probable and prefered is difficult. This could however be considered a benefit, since it EFE is a composite of utility gain and information.

## The aim of this paper

This potential benefit to adaptive therapy could be realized if adaptive therapy is modelled as a system where the tumor burden emits a noised signal. While controlling the tumor burden in short run is imperevative, truly successful strategies will have to also control future resistance dynamics. This task seems more challengig since resistance dynamics don't appear directly observable in clinical settings. Two obvious choices emerge, either implement a heuristic such which we expect to control the resistance dynamics well, or explicitly model the resistance dynamics despite paucity of real-time data on resistance. However, by applying a treatment and orbserving how the changes in tumor burden, the underlying resistance dynamics should be inferable. This paper invesitagets whether active inference can be used to gain traction on the second strategy.

Consider the following motivations for using Active Inference:

-   Real-time data will be sparse in the clinical settings. Extracting the maximum amount of infomraiton for each data point could be pivotal. Certain implementations of Active inference purpotedly approximate optimal bayesian inference.

-   Short-term exploiting tumor vulnerability is essential for keeping the patient alive, but for long term success, but controlling resistance dynamics is essential. A therapy plan will have to balance keeping the patient alive now against limiting its future options for treating. Since the degree of resistance is not directly

-   Gaining information about how the resistance dyanimcs is also essential and this must be done through treating the tumor. Choosing whether to treat would therefore not only be a consideration of the tumor level, but also about how much wiser it would make us about learning the resistance dynamics.

-   If the resitance level is only inferable through orbserving the treatment efficacy, the expected information gain from observing tumor the burden, i.e. testing, will differ between periods of treatment and non treatment. All else being equal, testing would therefore be more valuable during treatment.

An interesting corollary is that two patients could have the excatly the same tumor burden, but if the resitance dynamics is well modelled for one, treating could be poor choice. But the other patient could have excatly the have the same tumor burden, applying treatment could be the optimal move simpllearn about the resistance dynamics of their cancer. Due its approximations of bayesian inference and its ability to make utility information tradeoffs when deciding on actions, active inference seems to be promising paradigm planning adaptive therapy. By constructing simulating a simplified disctrete enviroment based on adaptive therapy, this paper will attempt to adapt the active inference implmentation of POMDPs in pymdp with the goal of keeping a virtual patient alive for as long as possible by inferring and controlling the tumor level in the short run and the resiostance level in the long run.

# Methods

## Simulation details

### Enviroment

The simulated enviroment features discretized of planning cancer treatments. At each timestep a "cancer state" has a certain risk of increasing. If the tumor ever reaches the state 5, the simulation ends. To avoid this, a model has decide when to apply treatment. Applying treatment can reduce the tumor level - whether the treatment succesfully reduces the "cancer state" depends on a underlying *resistance state*. When the resistance is low, the chance of treatment succeeding is high, but probability declines as the resistance state increase. The resistance state has fixed probability of increasing when treatment is applied, and it can decrease when treatment is withdrawn. Whether the resistance state decreases depends on the tumor level. At high tumor levels, the resistance state is more likely to decrease, but thiscarries the risk of tumor growing out of control and "killing the patient". In order to succesfully manage the disease, a model will therefore also have to manage the resistance state. However, the resistance state is directly orbserable in the given simulation. It must therefore be inferred from how the tumor state responds to treatment.

### Sim Runs:

Both the resistance state, and tumor states start at state 0 out of 5, meaning that a total is six states are possible in each. In both simulations, POMDPs transition matricies perfectly reflect the transition probabilties of the enviorment. Two slightly different simulations are used:

-   Performance simulation, where a range-bounded approach to managing the tumor is used, where the treatment is begun each time the tumor state increases above level 3, and is withdrawn when the tumor state drops below 2. 100 runs at 4 different probabilities of increasing the tumor state is run for maximally 200 timesteps. For each run, vectors of outcomes are pregenerated, meaning that vector of whether the tumor increases of length 200 is predetermined where each entry has the probability specified for the entire simulation. Likewise vectors are generated for treatment outcomes at each resistance level, and outcomes for resistance drops. This is done to ensure comparibility between the range-bounded approach and POMDP models that consider different future outcomes at different lengths. In these runs the tumor state is perfectly observable, meaning a tumor state always generates tumor observation that corresponds to hidden factor. The POMPD can only observe the tumor level, and its prior preferences are uniform over all tumor states except for the highest. These POMPDS only consider a combination of policies at each timestep. They can only consider treating or not treating for three timesteps in a row. The shortest horizon model only considers one of these blocks, while the medium considers two blocks of treating or not treating, for total horizon of 6 steps into the future. The longest horizon model considers three blocks for a total of 9 steps into the future. This is done to ease the computational burden, since it greatly reduces the total number of policies to be evaluated.

-   In the capacities simulation, a single run of a POMDP with a slightly different model structure is used. This model can observes a perfect signal of whether the patients is alive, whether the model is testing, treating and a noised signal of the tumor state if the model has decided to test the patient on the given run. Its prior preferences are heavily skewed against observing a dead patient, somewhat against treating and little against treating. This means that it will have to balance the "cost" of all these actions". It is also handicapped further by the fact that the tumor signal is noised, and the resistance state, which must be inferred through the tumor signal is therefore doubly obfuscated. The likelihood mapping between however perfectly captures the maps the expected noise.

### Changes to POMDP specification.

Hidden state factors do typically not affect each other at the state level. Instead their interactions are typically modelled as resulting from observations. This setup was deemed inadequate for the current experiment. It necessitated the that generative model could accurately model how the resistance state factor influences the probability of treatment succeeding. This was done in order to accurately portray issue of resistance levels generally being in accessible to current testing methodology and the evolutionary dynamics that are suspected to be at play in reducing resistance in real-world tumors.

Accurately modelling how higher tumor levels makes decreases in resistance more likely was also crucial. Typically, transition probabilties in the generative models are constructed using three dimensional "B-tensors", which describe expected transition probabilties within a state factor: one dimension the current state, one dimension for what ever action is chosen and third for the resulting state.

For the present project another dimension was added, this dimension corresponds to the state of another state factor. Concretely, this meant that the tumor state factor had fourth dimension. By matrix multiplication the expectation over this fourth dimension is factored in. One could choose to view it as there are now as many three dimensional b-tensors for the tumor state factor as there are states in the resistance factor. Effectively, matrix multiplying these result in a probability weighted average of expected tumor transition probabilities, i.e. the expectation. However, it should be noted that it is not trivial the order in which states are evaluated and that this must be specified. This also resulted in much pymdp functionality breaking, since it was presumably built only with three dimensional b-tensors in mind.

# Results

## Performance of POMDPs vs ADT heuristic

```{r}
#print densities
source("sim_lengths_densities_full.R")

plot + 
  #set color scheme so that long _vs_adt is green
  scale_fill_manual(values = strat_colors) +
  scale_color_manual(values = strat_colors) 



```

Four different simulation runs each consisting of 100 runs, of maximally 200 timesteps for different rates of tumor growth (respectively 1. .3, .5, and .7 probability of increasing the tumor state) . On each run the the outcomes on each of the potential 200 random variables are generated and each strategy is therefore tested on a the same enviroment. On the lowest tumor growth rate almost all the runs reach maximal length.

Contrasts against ADT-performance for growth rate .3, .5 and .7 are plotted. .1 is omitted since it appears that maximal perforamnce was achieved for each policy horizon of the POMPD strategies.

```{r}
source("contrasted_sim_lengths_.R")

plot +
  scale_fill_manual(values = contrast_colors) +
  scale_color_manual(values = contrast_colors) 
  
```

Two interpretations emerge from the contrasted simulation lengths. As the the growth rate increases, the POMDP seems to run for longer than the specific instance of the range bounded approach. It also seems that longer policy horizon seems beneficial. When the tumor state had .7 probability of increasing each timestep, the longest POMPD with the longest policy horizon performed as follows.

```{r}
source("contrasted_sim_length_max_horizon.R")

plot +
  scale_fill_manual(values = contrast_colors) +
  scale_color_manual(values = contrast_colors) 
```

At more aggressive cancer rates, the simulation consistently to outperform the range bounded approach. The absoulute increase in timesteps decreases however.

## Capabilities

### Learning underlying hidden state

The POMDP structure is capable of inferring an underlying hidden state: the resistance state. Even though this not directly observable, this can be inferred to how the tumor state responds to treatment. Applying treatment for longer time without any beneficial effect would suggest that the resistance level is high, while immediately observing that the tumor level decreases would suggest that the resistance level is low. At each timestep the POMDPs perform infer the most likely state of every state factor, given their current observation and prior beliefs. Through custom changes to the 'get_expected_states' function in PYMDP that allowed the models to consider how one hidden state factor (resistance factor) would influence another (the tumor factor).

```{r}
source("few_time_steps_res_beliefs.R")

plot

```

The above plot shows the strength of beliefs in t probabilities for a subset of timesteps [30 - 34], and the red dot show the actual the resistance levels. A time progresses the resistance level increases, and the model adjusts its beliefs. While the tumor level doesn't increase durings this time_period, this would also signal the model that the resistance level is low. This is the case since the enviroment always has change of increasing the tumor state, but such an increase would be negated by succesful round of treatment.

```{r}
source("sim_run_example.R")

plot

```

The entire run is plotted for the given. Only the tumor level is observable to the POMDP. It must combine its knowledge about how resistance level likely increases after applying treatment, and how the tumor level responds to treatment depenping on the the resistance level. While the model far from perfectly knows the resistance level. Model beliefs for the entire run is plotted.

```{r}
source("resistance_beliefs_plot.R")
plot
```

The model begins fairly agnostic. Given that the model was initialized with a uniform prior over resistance states this makes sense. Thorought out the course of the simulation it then finds loweer values of resistance state more likely.

### Beliefs, current/future and uncertainty is accessible

This current simulated model used a slightly different implementation than those compared to performance of rangebounded therapy planning. While the those models had longer policy horizons, they didn't consider the entire space possible actions. A model with a shorter policy horizon that would instead search every single possible action four steps is plotted to investigate the structure of decision-making by the POMDP model. The enviroment was also more unceartain. Instead of featuring a 1-to-1 mapping of the observations of the tumor to actual tumor state, it recieved a noised signal. It must therefore. The beliefs about how tumor state will evolve as a consequence of the most promising policy at time step 14 is plotted, and the expectation of resistance states at t=24 is plotted too.

```{r}
source("single_model_trajectories plot.R")
plot
```

Dotted vertical lines indicated the time-point for which the evaluation of expected states are extracted.

### Policy evalutation

```{r}
source("single_run_best policy.R")
plot
```

The above plot shows the highest evaluated policy at timestep 16 and at timestep 34. At timestep 16 not treatment is planned, and testing is withdrawn for next timestep but picked up again for reaminder of the period. For 34 treatment is suggested applied for three rounds. Note that policies are evaluated each timestep, and these plans are likely not finished. Instead a course of action is decided on each turn. The highest rated policy for each timestep is plotted

```{r}
source("single_run_overall_fep_policies.R")
plot
```

The above plot doesnt show realized actions but cumultatiove best action from perspective of each time point. This means that for completely blank spots, there is no point where model thinks treating or testing would be the optimal course of action. This doesn't never happen for treating, but some periods of treatment are throught time best held withdrawn. A darker shade indicate that on multiple prior timesteps, the model thought acting would be best course of action. Excact decision making for each policy can also be extracted. Since each policy is evaluated for its EFE, its expected information and utility gains can be extracted

```{r}
source("FEPcomponents.R")
plot

```

# Discussion

## What has this project found

The present project tested a simple modification of Active Inference POMDPs in simulated environment designed to mimic the dynamics of adaptive therapy. The modification allowed the POMDP to model an underlying resistance state that controlled the efficacy of treatment, despite the underlying state not producing any observable signals itself. This underscores the prospective of using the paradigm of active inference generally to plan adaptive therapies, and in particular has shown that under simplifed circumstances, POMDPs could be a useful choice of model to implement active inference for real-time adaptive therapy control.

Additionally, the paper demonstrates that active inference implementation of POMPS show a number of desirable qualities for adaptive therapy POMDPs:

-   The models are flexible. Computation and our ability to inform likelihood and transition dynamics, are the only limit to the combinations of hidden states, actions and outcome modalities. This present paper implemented a pomp capapble of combining multiple decisions, treating and testing, but more complex generative models could including multiple testing and treatment actions. Likewise, as [@west2023] highlight desiderata of biological factors that would be important to incorporate into modelling decisions.

-   A second quality is the capacity to balance expected information gain is balanced against expected utility. The certainty of the model is incorpareted directly in selecting when to apply treatments and when to test. From these considerations suggest that there is more information to be gained from testing when treatment is being applied, since it provides a view into the underlying resistance dynamics. Immediate testing seem to suggest that the models are more likely to apply testing when also applying treatment. Another interesting corrolary is that a POMPD could believe that two patients have exactly the same tumor burden but suggest treatment for one, but and not the other. This a feature, not a bug. If the model is certain about an underlying state (e.g. a resistance for the models in the present paper) there is less gain in information from treating. On the other hand, if the model is uncertain about the resistance state, it might be worthwhile to treat, simply for gain in information. This is appropriate behavior, since it allows the model better is chances of keeping the patient alive in the future.

-   Another quality of models desired [@west2023] is the rigorous unceartainty. Since the POMDP's certainty about current and future states is easily extractable, this criteria is arguably met. Additionally, its "reasoning", i.e. free energy estimates can be examined for each action.

## Future research

While the results are initially promising, the simple nature of the simulation prohibits drawing any strong conclusions about whether active inference POMPDs eventually could come to be a good model choice in a clinical setting.

The environment featured only discrete values. Since bio markers and dosage intensities often will be continuous space, some combination of binning continuous values to discrete values or building a model structure that can work with contious data is necessary. Deep-learning have for example been used to construct likelihood mappings and transition probabilities in POMDPs @çatal2020.

## Would longer policy search be better

Perhaps one could built a two-layer model. The bottom layer controls what goes inside the treatment-cycle, like the mountain-car controller. The top layer would the have to decide what of the different controllers to use. This

## Only one range bound

## Future Research

### NESS

Especially POMPDs but also other models have been used to model the decision of agents in active inference. Especially in psychopathology, human decision making has been modeled through these. This presents a fairly speculative, but interesting possibilty. It could potentially allow to approximate the decsision making of otherwise black box models. Perhaps if suitable controller could be designed for example by machine learning or another process leading to an opaque decision making process. POMPD should be fit table to its behavior and the model's decision making would thus become transparet. It would likely come with a cost to performance, but perhaps such a trading some performance for transparency could be worthwhile in a clinical setting.

This approach obviously isn't any better than our ability to construct such a black-box model and evaluate is performance prior to clinical trials.

### Priors over policies

One could also enforce a prior over an adaptive therapy approach, making sure that the model would only deviate from this if its very certain. This could hopefully combine the benefits and robustness of the 50% rule of thumb wiht the capacities of active inference.

### Continuous state space or binning illness

Moving from continous biomarkers to discrete data will be neccesary. either by reformulating pompds out for the discrete state space, or by binning, transforming observations into discrete values. Perhaps by diemnstionality reducition such as PCA, deep-neural networks, or simply binning observations. For example a tumor state could correspond to a 10% increase in tumor burden. Considering that they grow exponentially, this could perhaps result in the states occuupying the same amount of time/width of the underlying continous distreibution.

### Learning the transition parameters

Learning the transistion parameters, could happen through some comibnation of learning on the fly and prespecifcation by experet/knowledge modelling. Deep-learning on simulation data could probably be used. Perhaps also on already fitted data.

### Searching Policy Space better

### 

### Demonstrating the usefullness of models in adaptive therapy

An approach to demonstarting the usefullness of POMDP active inference model could be to show that it manages to control tumor progression succesfully on more realisting simulations, such as the Zhang et al. 2017 model. Either learning likelihood and transistion probabilities on the fly or specifiying them in a manner before hand that could be done in clinical setting too would be neccessary. Even more impressive would be a model that would given no chance to act, but only observe, accurately predict the actual outcomes of clinical data. For example the trial data reported. If this model would make interesting post-dictions, about better courses of actions, this would be severly interesting. It would still be hard to beat a rct.

### Other fep models

### 
