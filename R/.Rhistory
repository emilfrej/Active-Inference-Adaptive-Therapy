geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme(legend.position = "none") +
theme_minimal()
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme(legend.position = "none") +
theme_minimal()
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none")
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none") +
#remap y values to the inverse logit
scale_y_continuous(labels = scales::logit_format())
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none") +
#remap y values to the inverse logit
scale_y_continuous(trans = "logit")
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none") +
#remap y values to the inverse logit
scale_y_continuous(trans = "logit")
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(0,1)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none") +
#remap y values to the inverse logit
scale_y_continuous(trans = "logit")
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none") +
#remap y values to the inverse logit
scale_y_continuous(trans = "logit") +
ylim(0,1)+
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none") +
#remap y values to the inverse logit
scale_y_continuous(trans = "logit") +
ylim(0,1)
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none") +
#remap y values to the inverse logit
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Regression lines for the interaction",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none")
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Sampled Regression Lines for Each Combination of Gender and Class",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none")
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Sampled Regression Lines",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none")
View(m1.2)
# Make 2-3 copies of your model with different priors, compare them.
m1.2_sig_0.1 <- ulam(
alist( survived ~ dbinom( 1 , p ) ,
logit(p) <- a[gen_class_index] + b[gen_class_index] * age_std ,
a[gen_class_index] ~ dnorm( 0 , 0.1 ) ,
b[gen_class_index] ~ dnorm( 0 , 0.1 )
) , data = data_list )
m1.2_sig_1 <- ulam(
alist( survived ~ dbinom( 1 , p ) ,
logit(p) <- a[gen_class_index] + b[gen_class_index] * age_std ,
a[gen_class_index] ~ dnorm( 0 , 0.1 ) ,
b[gen_class_index] ~ dnorm( 0 , 0.1 )
) , data = data_list )
data_list <- list(
survived = d_processed$survived ,
age_std = d_processed$age_std ,
gen_class_index = d_processed$gen_class_index
)
# pre-processing variables
d_processed <- data.frame(
survived = as.numeric(d$Survive <- ) - 1 ,
# pre-processing variables
d_processed <- data.frame(
survived = as.numeric(d$Survive <- ) - 1 ,
# pre-processing variables
d_processed <- data.frame(
survived = as.numeric(d$Survived) - 1 ,
gender = as.numeric(d$is_female) + 1 ,
class = as.numeric(d$Pclass) ,
age_std = standardize(d$Age)
)
# making the gen_class_index variable and adding to the processed data frame
d_processed$gen_class_index <- ifelse( d_processed$gender == 1 , d_processed$gender * d_processed$class , (d_processed$gender-1) * d_processed$class + 3 )
# omitting NAs
d_processed <- na.omit(d_processed)
# computing correlation between gender and age
cor( d_processed$gender , d_processed$age_std )
data_list <- list(
survived = d_processed$survived ,
age_std = d_processed$age_std ,
gen_class_index = d_processed$gen_class_index
)
# fitting logistic regression model with interaction
m2.1 <- ulam(
alist( survived ~ dbinom( 1 , p ) ,
logit(p) <- a[gen_class_index] + b[gen_class_index] * age_std ,
a[gen_class_index] ~ dnorm( 0 , 0.5 ) ,
b[gen_class_index] ~ dnorm( 0 , 0.5 )
) , data = data_list )
# fitting logistic regression model with interaction
m2.1 <- ulam(
alist( survived ~ dbinom( 1 , p ) ,
logit(p) <- a[gen_class_index] + b[gen_class_index] * age_std ,
a[gen_class_index] ~ dnorm( 0 , 0.5 ) ,
b[gen_class_index] ~ dnorm( 0 , 0.5 )
) , data = data_list )
# Make 2-3 copies of your model with different priors, compare them.
m2.1_sig_0.1 <- ulam(
alist( survived ~ dbinom( 1 , p ) ,
logit(p) <- a[gen_class_index] + b[gen_class_index] * age_std ,
a[gen_class_index] ~ dnorm( 0 , 0.1 ) ,
b[gen_class_index] ~ dnorm( 0 , 0.1 )
) , data = data_list )
m2.1_sig_1 <- ulam(
alist( survived ~ dbinom( 1 , p ) ,
logit(p) <- a[gen_class_index] + b[gen_class_index] * age_std ,
a[gen_class_index] ~ dnorm( 0 , 0.1 ) ,
b[gen_class_index] ~ dnorm( 0 , 0.1 )
) , data = data_list )
# Make 2-3 copies of your model with different priors, compare them.
m2.1_sig_0.1 <- ulam(
alist( survived ~ dbinom( 1 , p ) ,
logit(p) <- a[gen_class_index] + b[gen_class_index] * age_std ,
a[gen_class_index] ~ dnorm( 0 , 0.1 ) ,
b[gen_class_index] ~ dnorm( 0 , 0.1 )
) , data = data_list, Log_lik = TRUE)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, rethinking)
d <- read_csv("~/.local/share/rstudio/RProjekter/portfolio-3-group-ate/data/titanic_train.csv")
# Making new gender coding
library(tidyverse)
d <- d %>% mutate(
is_female = case_when(
Sex == "female" ~ 1,
Sex == "male" ~ 0 )
)
library(rethinking)
#simplehist(d$is_female)
simplehist(d$Survived)
jitt_x = runif( n=length(d$Survived) , min=-.1 , max=.1 )
jitt_y = runif( n=length(d$Pclass) , min=-.1 , max=.1 )
col_vec = ifelse( d$is_female==1 , "green" , "blue" )
plot( x=d$Survived + jitt_x , y=d$Pclass + jitt_y , col=col_vec )
library(dagitty)
dag1.1 <- dagitty( "dag{ A -> C -> S ; A -> S ; G -> C ; G -> S }" )
coordinates( dag1.1 ) <- list( x=c(S=1, A=0, G=2, C=1) , y=c(S=2,A=0,G=0, C=0) )
drawdag( dag1.1 )
# checking distribution
library(tidyverse)
d_female_subset <- d[d$Sex == "female" ,]
freq_table <- d %>% group_by(Pclass) %>% count(Sex)
fm_prop_c1 <- freq_table[1:2,3]/sum(freq_table[1:2,3])
fm_prop_c2 <- freq_table[3:4,3]/sum(freq_table[3:4,3])
fm_prop_c3 <- freq_table[5:6,3]/sum(freq_table[5:6,3])
round(fm_prop_c1, 2)
round(fm_prop_c2, 2)
round(fm_prop_c3, 2)
# setting up simulation size and simulating gender and age distributions
N <- 1000
gender <- rbinom( n = N , size = 1 , prob = .35 ) # 0 = male, 1 = female
age <- truncnorm::rtruncnorm( n = N , a = 0 , b = 80 , mean = 30 , sd = 15)
# hist(gender)
# hist(age)
# defining a data frame
d_sim <- list()
d_sim$gender <- gender
d_sim$age <- age
d_sim <- data.frame(d_sim)
# checking the age distribution across gender
# g_1 <- d[d$gender == 1,]
# g_0 <- d[d$gender == 0,]
#
# hist(g_0$age)
# hist(g_1$age)
# assigning classes according to gender and age bin
# making categorical age variable.
# the oldest age group has the integer value 3, next oldest 2, the youngest 1
d_sim <- d_sim %>% mutate(age_bin = ifelse( age < 19 , 1 ,
ifelse( age < 45 , 2 , 3)
) )
# assigning class probabilities based on three age bins
A <- d_sim$age_bin
G <- d_sim$gender
0.2*(1-1)
p_class_1 <- ifelse( G == 0 , 0.1 , 0.1 ) + ifelse( A == 3 , 0.3 , 0 ) # favors the older bins
p_class_2 <- ifelse( G == 0 , 0.25 , 0.25 )
p_class_3 <- ifelse( G == 0, 0.4 , 0.2 ) + ifelse( A < 3 , 0.3 , 0 ) # favors the younger bins
p_list <- data.frame( p_class_1 , p_class_2 , p_class_3 )
# normalizing probabilities row wise to make sure they sum to one
norm_p_list <- t(apply(p_list, 1, function(row) row / sum(row)))
norm_p_list <- data.frame(norm_p_list)
# checking that every row sums to one
unique(apply(norm_p_list, 1, function(row) sum(row)))
# assigning gender by probability list
for (i in 1:nrow(d_sim)) {
d_sim$class[i] <- sample(x = 1:3, size = 1, prob = norm_p_list[i,])
}
# Checking the gender grouping for each class in both the actual and the sim data
d_sim %>% group_by(class) %>% count(gender)
d %>% group_by(Pclass) %>% count(Sex)
# simulating survival rate
# defining simulation parameters
C <- d_sim$class
G <- d_sim$gender
A <- d_sim$age_bin
class_coefficient = 0.15
# trying out the mechanics
1 - class_coefficient * (3)
1 - class_coefficient * (2)
1.1 - class_coefficient * (1)
# drawing survival rates from a Bernoulli distribution
d_sim$survived <- rbern( N , p = ifelse( A==1 , 1 - C*class_coefficient , # children p
ifelse( G==1 , 1 - C*class_coefficient , # non-child female p
0.1 + (3-C)*class_coefficient ) ) # non-child male p
)
library(ggplot2)
# changing variable types and levels in sim data
d_sim$survived <- as.factor(d_sim$survived)
d_sim$gender_factor <- as.factor(d_sim$gender)
levels(d_sim$gender_factor) <- c( "male" , "female" )
# changing variable types and levels in actual data
d$Survived <- as.factor(d$Survived)
d$is_female <- as.factor(d$is_female)
levels(d$is_female) <- c( "male" , "female" )
# defining variables for plots
alpha <- 0.7
ps <- 0.7
# making plots for simulated and actual data
sim_plot_wrap <- ggplot( data = d_sim ,
aes( x = age , y = jitter(class, 0.5) ,
color = survived ,
shape = gender_factor ) ) +
geom_point(size = ps , alpha = alpha) +
facet_wrap(~gender_factor) +
labs(y = "" , subtitle = "Sim. data wrapped by gender") +
theme(legend.position = "none")
sim_plot <- ggplot( data = d_sim ,
aes( x = age , y = jitter(class, 0.5) ,
color = survived ,
shape = gender_factor ) ) +
geom_point(size = ps , alpha = alpha) +
labs(y = "Class" , subtitle = "Sim. data") +
theme(legend.position = "none")
act_plot_wrap <- ggplot( data = d ,
aes( x = Age , y = jitter(Pclass, 0.5) ,
color = Survived ,
shape = is_female ) ) +
geom_point(size = ps , alpha = alpha) +
facet_wrap(~is_female) +
labs(y = "", subtitle = "Actual data wrapped by gender") +
theme(legend.position = "none")
act_plot <- ggplot( data = d ,
aes( x = Age , y = jitter(Pclass, 0.5) ,
color = Survived ,
shape = is_female ) ) +
geom_point(size = ps , alpha = alpha) +
labs(y = "Class", subtitle = "Actual data") +
theme(legend.position = "none")
cowplot::plot_grid( sim_plot , sim_plot_wrap , act_plot , act_plot_wrap ,
ncol = 2 , nrow = 2)
drawdag( dag1.1 )
adjustmentSets( dag1.1 , exposure = "C" , outcome = "S")
# preparing the fit
# checking variable names and recoding the gender factor to integer: 1 = male, 2 = female
colnames(d_sim)
levels(d_sim$gender_factor)
d_sim$gender_integer <- as.integer(d_sim$gender_factor)
# creating data list, changing data types, and standardizing the continuous age variable
data_list <- list(
survived = as.numeric(d_sim$survived) - 1 , # converting this to a 0 or 1 numerical variable
gender = as.numeric(d_sim$gender_integer) ,
class = as.numeric(d_sim$class) ,
age_std = standardize(d_sim$age)
)
# fitting logistic regression model without any interactions
m1.1 <- ulam(
alist( survived ~ dbinom( 1 , p ) ,
logit(p) <- b_c[class] + b_g[gender] + b_a*age_std , # fix this, look into ch. 8.
b_c[class] ~ dnorm( 0 , 0.5 ) ,
b_g[gender] ~ dnorm( 0 , 0.5 ) ,
b_a ~ dnorm( 0 , 0.5 )
) , data = data_list )
# making new combinatorial variable
gen_class_index <- ifelse( d_sim$gender_integer == 1 , d_sim$gender_integer * d_sim$class , (d_sim$gender_integer-1) * d_sim$class + 3 )
# assembling new data list
data_list <- list(
survived = as.numeric(d_sim$survived) - 1 ,
gender = as.numeric(d_sim$gender_integer) ,
class = as.numeric(d_sim$class) ,
age_std = standardize(d_sim$age) ,
gen_class_index = gen_class_index
)
data.frame(data_list)
# fitting a logistic regression model including a three way interaction
m1.2 <- ulam(
alist( survived ~ dbinom( 1 , p ) ,
logit(p) <- a[gen_class_index] + b[gen_class_index] * age_std ,
a[gen_class_index] ~ dnorm( 0 , 0.5 ) ,
b[gen_class_index] ~ dnorm( 0 , 0.5 )
) , data = data_list )
# assessing the output
precis( m1.2 , depth = 2 )
# prior predictive check
# sampling from the priors
set.seed(1912)
prior <- extract.prior( m1.1 , n = 1e4 )
# returning the coefficient for p to the non-log probability space
p <- sapply( 1:3 , function(k) inv_logit( prior$b_c[,k] ) )
dens( p[,1] - p[,3], adj = 0.1 , main = "Prior predictive check: p class 1 - p class 3", col=rangi2, xlim = c(-0.6, 0.6))
dens( p[,1] - p[,2], adj = 0.1 , main = "Prior predictive check: p class 1 - p class 2" , col=rangi2, xlim = c(-0.6, 0.6))
dens( p[,2] - p[,3], adj = 0.1 , main = "Prior predictive check: p class 2 - p class 3" , col=rangi2, xlim = c(-0.6, 0.6))
# printing the implied conditional independencies
impliedConditionalIndependencies( dag1.1 )
coefficient_m1.2 <- extract_post_ulam(m1.2)
#extract alphas from sampled coefficients
alphas <- coefficient_m1.2$a %>%
#turn into dataframe
data.frame() %>%
#pivot into long format so there is only one row of alphas
pivot_longer(cols = everything(), names_to = "gen_class_index", values_to = "alphas") %>%
#remove X from strings
mutate(gen_class_index = str_remove(gen_class_index, "X")) %>%
mutate(gen_class_index = as.numeric(gen_class_index))
#do the same for betas
betas <- coefficient_m1.2$b %>%
data.frame() %>%
pivot_longer(cols = everything(), names_to = "gen_class_index", values_to = "betas") %>%
mutate(gen_class_index = str_remove(gen_class_index, "X")) %>%
mutate(gen_class_index = as.numeric(gen_class_index))
#merge alphas and betas (without gen_class_index) into one dataframe
regression_lines_m1.2 <- cbind(alphas, betas$betas) %>%
#rename
rename(betas = 'betas$betas')
#Turn gen_class_index into a factor
regression_lines_m1.2 <- regression_lines_m1.2 %>%
mutate(gen_class_index = as.factor(gen_class_index))
levels(regression_lines_m1.2$gen_class_index) <- c("Men First Class", "Men Second Class", "Men Third Class", "Women First Class", "Women Second Class", "Women Third Class")
ggplot(regression_lines_m1.2, aes(color = gen_class_index)) +
geom_abline(aes(intercept = alphas, slope = betas, color = gen_class_index), alpha = 0.1 ) +
xlim(-5,5)+
ylim(-5,5)+
facet_wrap(~gen_class_index) +
labs(title = "Sampled Regression Lines",
x = "Age Std",
y = "Logodds of Surviving") +
#remove the legend
theme_minimal() +
theme(legend.position = "none")
# pre-processing variables
d_processed <- data.frame(
survived = as.numeric(d$Survive <- ) - 1 ,
plogis(2)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
# set the directory to visualizations folder
pacman::p_load(tidyverse, ggnewscale)
theme_set(theme_classic())
#set colors
adt_col <- "green"
long_col <- "red"
medium_col <- "skyblue"
short_col = "violet"
strat_colors <- c("ADT" = adt_col, "Long" = long_col, "Medium" = medium_col, "Short" = short_col)
contrast_colors <- c("long_vs_adt" = long_col, "medium_vs_adt" = medium_col, "short_vs_adt" = short_col)
#print densities
source("sim_lengths_densities_full.R")
plot +
#set color scheme so that long _vs_adt is green
scale_fill_manual(values = strat_colors) +
scale_color_manual(values = strat_colors)
source("contrasted_sim_lengths_.R")
plot +
scale_fill_manual(values = contrast_colors) +
scale_color_manual(values = contrast_colors)
source("contrasted_sim_length_max_horizon.R")
plot +
scale_fill_manual(values = contrast_colors) +
scale_color_manual(values = contrast_colors)
source("few_time_steps_res_beliefs.R")
plot
source("sim_run_example.R")
plot
source("resistance_beliefs_plot.R")
plot
source("single_model_trajectories plot.R")
plot
knit_with_parameters("~/Desktop/Socult Exam/R/SocultPaperV6.Rmd")
source("~/.active-rstudio-document", echo=TRUE)
setwd("~/Desktop/Socult Exam/R")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.height = 3, fig.width = 5, fig.align = "center")
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
#load pacakages
pacman::p_load(tidyverse, ggnewscale, patchwork)
## Graphical settings ##
#set themes
theme_set(theme_classic())
#set colors
rb_col <- "green"
long_col <- "red"
medium_col <- "skyblue"
short_col = "violet"
strat_colors <- c("RB" = rb_col, "Long" = long_col, "Medium" = medium_col, "Short" = short_col)
contrast_colors <- c("Long Horizon POMPD vs RB" = long_col, "medium_vs_rb" = medium_col, "short_vs_rb" = short_col)
source("ReadInData.R")
source("sim_run_example.R")
plot
